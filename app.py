import gradio as gr
import numpy as np
from PIL import Image
import time
import torch
from diffusers import FluxPipeline
from scripts.DNAEdit_utils import DNAEdit_FLUX

def edit_image(image, source_prompt, target_prompt, t_step, mvg, t_start, cfg):
    """
    å›¾åƒç¼–è¾‘å‡½æ•°
    
    å‚æ•°:
        image: è¾“å…¥çš„PILå›¾åƒ
        source_prompt: æºæç¤ºè¯
        target_prompt: ç›®æ ‡æç¤ºè¯
        t_step: T_stepå‚æ•°
        mvg: MVGå‚æ•°
        t_start: T_startå‚æ•°
        cfg: CFGå‚æ•°
        progress: Gradioè¿›åº¦æ¡å¯¹è±¡
    
    è¿”å›:
        edited_image: ç¼–è¾‘åçš„PILå›¾åƒ
    """
    if image is None:
        gr.Warning("è¯·å…ˆä¸Šä¼ å›¾ç‰‡ï¼")
        return None
    
    if not source_prompt or not target_prompt:
        gr.Warning("è¯·è¾“å…¥æºæç¤ºè¯å’Œç›®æ ‡æç¤ºè¯ï¼")
        return None
    #
    global loaded_pipe
    
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²åŠ è½½
    if loaded_pipe is None:
        gr.Warning("è¯·å…ˆåŠ è½½æ¨¡å‹ï¼")
        return None
    pipe = loaded_pipe
    # æ€»è¿­ä»£æ­¥æ•°ï¼ˆæ ¹æ®ä½ çš„æ¨¡å‹è°ƒæ•´ï¼‰
    image = image.crop((0, 0, image.width - image.width % 16, image.height - image.height % 16))
    original_width, original_height = image.size
    image = image.resize((original_width,original_height),Image.BILINEAR)
    image_src = pipe.image_processor.preprocess(image)
    image_src = image_src.to("cuda").half()
    with torch.autocast("cuda"), torch.inference_mode():
                x0_src_denorm = pipe.vae.encode(image_src).latent_dist.mode()
    x0_src = (x0_src_denorm - pipe.vae.config.shift_factor) * pipe.vae.config.scaling_factor
    # send to cuda
    x0_src = x0_src.to("cuda")
    x0_tar = DNAEdit_FLUX(loaded_pipe,
                                                        pipe.scheduler,
                                                        x0_src,
                                                        source_prompt,
                                                        target_prompt,
                                                        "",
                                                        t_step,
                                                        1,
                                                        cfg,
                                                        mvg=mvg,
                                                        T_start=t_start)
    x0_tar_denorm = (x0_tar / pipe.vae.config.scaling_factor) + pipe.vae.config.shift_factor
    with torch.autocast("cuda"), torch.inference_mode():
        image_tar = pipe.vae.decode(x0_tar_denorm, return_dict=False)[0]
    image_tar = pipe.image_processor.postprocess(image_tar)
    image_tar = image_tar[0].resize((original_width,original_height),Image.BILINEAR)
    edited_image = image_tar
    
    # ========================================================================
    
    return edited_image



loaded_pipe = None
loaded_scheduler = None

def load_model(model_type, progress=gr.Progress()):
    """
    åŠ è½½æ¨¡å‹å‡½æ•°
    
    å‚æ•°:
        model_choice: é€‰æ‹©çš„æ¨¡å‹åç§°
        progress: Gradioè¿›åº¦æ¡å¯¹è±¡
    
    è¿”å›:
        status_message: åŠ è½½çŠ¶æ€ä¿¡æ¯
    """
    global loaded_pipe, loaded_scheduler
    
    try:
        progress(0.1, desc="æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹...")
        if model_type == 'FLUX':
        # pipe = FluxPipeline.from_pretrained("black-forest-labs/FLUX.1-schnell", torch_dtype=torch.float16) 
            pipe = FluxPipeline.from_pretrained("/home/notebook/data/personal/S9055029/hf/FLUX.1-dev", torch_dtype=torch.float16)
        elif model_type == 'SD3':
            pipe = StableDiffusion3Pipeline.from_pretrained("/home/notebook/data/personal/S9055029/hf/stable-diffusion-3.5-medium", torch_dtype=torch.float16)
        pipe.to("cuda")
        loaded_pipe=pipe
        loaded_scheduler = pipe.scheduler

        

        
        # ========================================================================
        
        return f"âœ… æ¨¡å‹ '{model_choice}' åŠ è½½æˆåŠŸï¼"
        
    except Exception as e:
        loaded_pipe = None
        loaded_scheduler = None
        return f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}"



# åˆ›å»ºGradioç•Œé¢
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown(
        """
        # ğŸ¨ DNAEdit Demo
        """
    )
    
    # æ¨¡å‹åŠ è½½åŒºåŸŸ
    with gr.Row():
        with gr.Column(scale=1):
            gr.Markdown("### ğŸ¤– æ¨¡å‹é…ç½®")
            model_choice = gr.Radio(
                choices=["FLUX"],
                value="FLUX",
                label="é€‰æ‹©æ¨¡å‹",
                info="é€‰æ‹©è¦ä½¿ç”¨çš„æ‰©æ•£æ¨¡å‹"
            )
        
        with gr.Column(scale=1):
            gr.Markdown("### ")
            load_model_btn = gr.Button(
                "â¬‡ï¸ åŠ è½½æ¨¡å‹",
                variant="primary",
                size="lg"
            )
            model_status = gr.Textbox(
                label="æ¨¡å‹çŠ¶æ€",
                value="âšª æœªåŠ è½½æ¨¡å‹",
                interactive=False,
                lines=1
            )
    
    gr.Markdown("---")
    
    with gr.Row():
        # å·¦ä¾§ï¼šè¾“å…¥åŒºåŸŸ
        with gr.Column(scale=1):
            gr.Markdown("### ğŸ“¤ è¾“å…¥å›¾ç‰‡")
            input_image = gr.Image(
                label="ä¸Šä¼ å›¾ç‰‡",
                type="pil",
                height=350
            )
            
            gr.Markdown("### ğŸ“ æç¤ºè¯è®¾ç½®")
            source_prompt = gr.Textbox(
                label="Source Promptï¼ˆæºæç¤ºè¯ï¼‰",
                placeholder="æè¿°åŸå§‹å›¾ç‰‡çš„å†…å®¹ï¼Œä¾‹å¦‚ï¼ša photo of a cat",
                lines=2,
                info="æè¿°è¾“å…¥å›¾ç‰‡å½“å‰çš„å†…å®¹"
            )
            
            target_prompt = gr.Textbox(
                label="Target Promptï¼ˆç›®æ ‡æç¤ºè¯ï¼‰",
                placeholder="æè¿°æœŸæœ›ç¼–è¾‘åçš„å†…å®¹ï¼Œä¾‹å¦‚ï¼ša photo of a dog",
                lines=2,
                info="æè¿°ä½ æƒ³è¦ç¼–è¾‘æˆçš„ç›®æ ‡å†…å®¹"
            )
            
            gr.Markdown("### âš™ï¸ ç¼–è¾‘å‚æ•°")
            
            with gr.Accordion("å‚æ•°è®¾ç½®", open=True):
                t_step = gr.Slider(
                    minimum=1,
                    maximum=100,
                    value=28,
                    step=1,
                    label="T_step",
                    info="æ§åˆ¶ç¼–è¾‘è¿­ä»£çš„æ€»æ­¥æ•°"
                )
                
                mvg = gr.Slider(
                    minimum=0.0,
                    maximum=1.0,
                    value=0.8,
                    step=0.1,
                    label="MVGç³»æ•°",
                    info="è¶Šå¤§çš„å€¼å›¾ç‰‡ç¼–è¾‘åŠ›åº¦è¶Šå¤§"
                )
                
                t_start = gr.Slider(
                    minimum=0,
                    maximum=20,
                    value=4,
                    step=1,
                    label="T_start",
                    info="è¶Šå°çš„å€¼å›¾ç‰‡ç¼–è¾‘åŠ›åº¦è¶Šå¤§"
                )
                
                cfg = gr.Slider(
                    minimum=1.0,
                    maximum=10.0,
                    value=2,
                    step=0.5,
                    label="CFG",
                    info="è¶Šå¤§çš„å€¼å›¾ç‰‡ç¼–è¾‘åŠ›åº¦è¶Šå¤§"
                )
            
            edit_btn = gr.Button(
                "ğŸš€ å¼€å§‹ç¼–è¾‘",
                variant="primary",
                size="lg"
            )
        
        # å³ä¾§ï¼šè¾“å‡ºåŒºåŸŸ
        with gr.Column(scale=1):
            gr.Markdown("### ğŸ“¥ ç¼–è¾‘ç»“æœ")
            output_image = gr.Image(
                label="ç¼–è¾‘åçš„å›¾ç‰‡",
                type="pil",
                height=350
            )
            
            gr.Markdown("### ğŸ“Š å½“å‰é…ç½®")
            with gr.Accordion("é…ç½®è¯¦æƒ…", open=True):
                config_display = gr.Markdown()
    
    # æ›´æ–°é…ç½®æ˜¾ç¤º
    def update_config(source_prompt, target_prompt, t_step, mvg, t_start, cfg):
        return f"""
        **æç¤ºè¯é…ç½®ï¼š**
        - **Source Prompt**: {source_prompt if source_prompt else 'æœªè®¾ç½®'}
        - **Target Prompt**: {target_prompt if target_prompt else 'æœªè®¾ç½®'}
        
        **å‚æ•°é…ç½®ï¼š**
        - **T_step**: {t_step}
        - **MVG**: {mvg}
        - **T_start**: {t_start}
        - **CFG**: {cfg}
        """
    
    # ç›‘å¬æ‰€æœ‰å‚æ•°å˜åŒ–
    for param in [source_prompt, target_prompt, t_step, mvg, t_start, cfg]:
        param.change(
            fn=update_config,
            inputs=[source_prompt, target_prompt, t_step, mvg, t_start, cfg],
            outputs=config_display
        )
    
    # åŠ è½½æ¨¡å‹æŒ‰é’®ç‚¹å‡»äº‹ä»¶
    load_model_btn.click(
        fn=load_model,
        inputs=[model_choice],
        outputs=model_status
    )
    
    # ç‚¹å‡»ç¼–è¾‘æŒ‰é’®
    edit_btn.click(
        fn=edit_image,
        inputs=[input_image, source_prompt, target_prompt, t_step, mvg, t_start, cfg],
        outputs=output_image
    )
    
    # ç¤ºä¾‹
    gr.Markdown("### ğŸ’¡ ä½¿ç”¨æç¤º")
    gr.Markdown(
        """
        1. é¦–å…ˆåœ¨é¡¶éƒ¨ **é€‰æ‹©æ¨¡å‹** å¹¶ç‚¹å‡» **åŠ è½½æ¨¡å‹** æŒ‰é’®
        2. ç­‰å¾…æ¨¡å‹åŠ è½½å®Œæˆï¼ˆçŠ¶æ€æ˜¾ç¤ºä¸º âœ…ï¼‰
        3. ç‚¹å‡»å·¦ä¾§ **ä¸Šä¼ å›¾ç‰‡** åŒºåŸŸé€‰æ‹©è¦ç¼–è¾‘çš„å›¾ç‰‡
        4. åœ¨ **Source Prompt** ä¸­è¾“å…¥æè¿°åŸå§‹å›¾ç‰‡å†…å®¹çš„æç¤ºè¯
        5. åœ¨ **Target Prompt** ä¸­è¾“å…¥æè¿°ç›®æ ‡ç¼–è¾‘ç»“æœçš„æç¤ºè¯
        6. è°ƒæ•´ç¼–è¾‘å‚æ•°ä»¥è·å¾—æœ€ä½³æ•ˆæœ
        7. ç‚¹å‡» **å¼€å§‹ç¼–è¾‘** æŒ‰é’®å¯åŠ¨ç¼–è¾‘è¿‡ç¨‹
        8. ç¼–è¾‘è¿‡ç¨‹ä¸­å¯ä»¥çœ‹åˆ°è¿›åº¦æ¡æ˜¾ç¤º
        9. ç¼–è¾‘å®Œæˆåï¼Œç»“æœå°†æ˜¾ç¤ºåœ¨å³ä¾§
        
        **ç¤ºä¾‹æç¤ºè¯ï¼š**
        - Source: "a photo of a cat on the grass"
        - Target: "a photo of a dog on the grass"
        """
    )
    


# å¯åŠ¨åº”ç”¨
if __name__ == "__main__":
    demo.launch(
        share=True,
        server_name="0.0.0.0",
        server_port=7860
    )